---
title: "Introducción a probabilidad"
author: "Teresa Ortiz"
output:
  html_document:
    css: ../codigo-estilos/cajas.css
    theme: spacelab
  html_notebook:
    css: ../codigo-estilos/cajas.css
    theme: spacelab
---


>"Probabilidad es el lenguaje matemático para cuantificar incertidumbre."
> -Wasserman

En estas notas abordamos los siguientes temas:

1. Terminología de probabilidad: espacio de resultados, eventos, funciones de 
probabilidad.  
2. Interpretación frecuentista de probabilidad.
3. Probabilidad condicional y su relación con independencia.  
4. La regla de Bayes.  
5. Variables aleatorias: a qué se refieren.

<!-- Hadley:
"Probabilidad es la maquinaria matemática necesaria para responder preguntas de
eventos inciertos"
Kruschke:
"Probabilidad es simplemente una manera de asignar números a un conjunto de 
posibilidades mutuamente excluyentes."

La teoría de probabilidades tiene como problema
general describir mediante un modelo matemático cada tipo de fenómeno aleatorio,
mientras que la inferencia estadística tiene planteado el problema inverso, es decir, a
partir del conocimiento de una parte del fenómeno pretende establecer sus propiedades,
para lo cual forzosamente debe utilizar algún modelo probabilístico que describa
el fenómeno. Es esta dependencia de la estadística con la teoría de probabilidad lo que justifica profundizar el estudio de esta ultima.

-->

```{r, echo = FALSE, message=FALSE, error=TRUE}
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE
)
comma <- function(x) format(x, digits = 2, big.mark = ",")
options(digits=2)

library(tidyverse)
library(magrittr)
theme_set(theme_minimal())
```

### Espacio de resultados y eventos

<div class="caja">
El **espacio de resultados** $\Omega$ es el conjunto de posibles resultados de un
experimento aleatorio. A los puntos $\omega \in \Omega$ se les conoce como 
resultados muestrales, realizaciones o elementos.
</div>


Ejemplo: Si lanzamos una moneda dos veces entonces el espacio de resultados es:

$$\Omega = \{AA, AS, SA, SS \}$$

<div class="caja">
Un **evento** es un subconjunto del espacio muestral, los eventos usualmente se 
denotan por letras mayúsculas.
</div>

El evento: que la primer lanzamiento resulte águila es

$$A=\{AA, AS\}$$


#### Eventos equiprobables

La probabilidad se puede ver como una extensión de la idea de proporción, o cociente
de una parte con respecto a un todo. Si en la carrera de matemáticas del ITAM 
hay 300 estudiantes hombres y 700 mujeres, la proporción de hombres es:
$$\frac{300}{700+300}=0.3$$
Ahora, supongamos que elegimos un estudiante al azar, la probabilidad de elegir
una mujer es $0.7$.

En el ejemplo hay un supuesto implícito en elegir al azar (o aleatoriamente),
en este caso estamos suponiendo que todos los estudiantes tienen la misma 
probabilidad de ser elegidos, que nos lleva al siguiente concepto: 

<div class="caja">
**Eventos equiprobables**. Si todos los elementos en el espacio de resultados 
tienen la misma oportunidad de ser elegidos entonces la probabilidad del evento A 
es el número de resultados en A dividido entre el número total de posibles 
resultados:
</div>

$$P(A)=\frac{\#(A)}{\#(\Omega)}$$

Por lo que solo hace falta contar.

Por ejemplo, la probabilidad de obtener $AA$ si lanzamos una moneda dos veces
es $1/4 = 0.25$, y la probabilidad del evento que la primer lanzamiento resulte 
águila es $2/4 = 0.5$.

![](../imagenes/manicule2.jpg) Lanzamos un dado y anotamos el número de la cara
superior, después lanzamos otro dado y anotamos el número de la cara superior.

* ¿Cuál es el espacio de resultados?

* ¿Cuál es la probabilidad de que la suma de los números sea 5?  

* ¿Cuál es la probabilidad de que el segundo número sea mayor que el primero?  

* Repite las preguntas anteriores cuando lanzas 2 dados con $n$ caras ($n \ge 4$).

#### Ejemplo: combinaciones
Un comité de 5 personas será seleccionado de un grupo de 6 hombres y 9 mujeres. 
Si la selección es aleatoria, ¿cuál es la probabilidad de que el comité este
conformado por 3 hombres y 2 mujeres?

Hay $\dbinom{15}{5}$ posibles comités, cada uno tiene la misma posibilidad de ser seleccionado. Por otra parte, hay $\dbinom{6}{3} \dbinom{9}{2}$ posibles comités 
que incluyen 3 hombres y 2 mujeres, por
lo tanto, la probabilidad que buscamos es: 
$$\frac{\dbinom{6}{3} \dbinom{9}{2}}{\dbinom{15}{5}} $$

y la función para calcular combinaciones en R es _choose(n, r)_

```{r}
choose(6, 3) * choose(9, 2) / choose(15, 5)
```

### Interpretación frecuentista de probabilidad
Ya tenemos una interpretación intuitiva de probabilidad pero nos deja abierta
la pregunta de como interpretar probabilidades en aplicaciones. En el curso 
veremos dos interpretaciones de probabilidad: la interpretación 
frecuentista en la cuál las probabilidades se entienden como una aproximación
matemática de frecuencias relativas cuando la frecuencia total tiende a infinito. 
La segunda interpretación es la subjetiva en la que un enunciado de probabilidad 
expresa la opinión de un individuo respecto a la certeza de que ocurra un evento.

Por ahora nos concentramos en la interpretación frecuentista. Una frecuencia 
relativa es una proporción que mide que tan seguido, o frecuente, 
ocurre una u otra cosa en una sucesión de observaciones. Pensemos en un
experimento que se pueda repetir, por ejemplo, lanzar una moneda, lanzar un 
dado, el nacimiento de un bebé. Llamaremos ensayo a una repetición del 
experimento. Ahora, sea A un posible resultado del evento 
(obtener sol, obtener un 6, el bebé es niña), si A ocurre $m$ veces en
$n$ ensayos, entonces la frecuencia relativa de A en $n$ ensayos es $m/n$.


Supongamos que lanzamos una moneda 10 veces y obtenemos los siguientes resultados:

```{r}
lanzamientos_10 <- sample(c("A", "S"), 10, replace = TRUE)
lanzamientos_10
```

Podemos calcular las secuencia de frecuencias relativas de águila:

```{r}
cumsum(lanzamientos_10 == "A") # suma acumulada de águilas
cumsum(lanzamientos_10 == "A") / 1:10
```

Una regla general, es que las frecuencias relativas basados en un número 
mayor de observaciones son menos fluctuantes comparado con las frecuencias
relativas basadas en pocas observaciones. Este fenómeno se conoce como la **ley 
empírica de los promedios**:

```{r, fig.width=8.2, fig.height=3.8}
n <- 1000
data_frame(num_lanzamiento = 1:n, lanzamiento = sample(c("A", "S"), n, replace = TRUE)) %>% 
    mutate(frec_rel = cummean(lanzamiento == "A")) %>%
    ggplot(aes(x = num_lanzamiento, y = frec_rel)) +
        geom_hline(yintercept = 0.5, color = "red", alpha = 0.5) +
        geom_line(color = "darkgray") +
        geom_point(size = 1.0) +
        labs(y = "frecuencia relativa", title = "1000 volados", x = "lanzamiento")
```

Veamos las frecuencias relativas para 3 series de 1000 lanzamientos.

```{r, fig.width=8.2, fig.height=3.8}
lanzar <- function(n = 1000){
    data_frame(num_lanzamiento = 1:n, lanzamiento = sample(c("A", "S"), n, replace = TRUE)) %>% 
        mutate(frec_rel = cummean(lanzamiento == "A"))
  }
head(lanzar())

set.seed(31287931)
# usamos la función map_df del paquete purrr
map_df(1:3, ~lanzar(), .id = "serie") %>% 
    ggplot(aes(x = log(num_lanzamiento), y = frec_rel, color = as.character(serie))) +
        geom_hline(yintercept = 0.5, color = "darkgray") + 
        geom_line() +
        scale_x_continuous("lanzamiento", labels = exp, 
            breaks = log(sapply(0:10, function(i) 2 ^ i))) +
        labs(color = "serie", y = "frecuencia relativa", title = "1000 volados")
```

<div class="caja">
En la **interpretación frecuentista**, la probabilidad de un evento $A$ es la 
estimación de la frecuencia relativa de $A$ cuando el número de ensayos tiende
a infinito. Si denotemos la proporción de veces que ocurre $A$ en $n$ ensayos por 
$P_n(A)$, se espera que $P_n(A)$ sea cercana a la probabilidad $P(A)$ si $n$ 
es _grande_:
$$P_n(A) \approx P(A)$$
</div>

Esta idea se precisará más adelante cuando estudiemos la 
**ley de los grandes números**.

Veamos un ejemplo de probabilidad como frecuencia relativa; el objetivo es 
entender cómo la interpretación frecuentista nos da el nivel de detalle correcto 
cuando suponemos resultados equiprobables.

##### Ejemplo: Lanzamiento de dos monedas
Supongamos que lanzamos dos monedas de manera simultánea. ¿Cuál es la 
probabilidad de que las dos monedas sean águila?

* Las dos son águila o no, así que la posibilidad es 1/2.

* Si definimos el resultado como el número de caras que se leen en las monedas, 
puede haber 0, 1 o 2. Si suponemos que estos tres resultados son igualmente
probables, entonces la posibilidad es 1/3.

* A pesar de que las monedas son similares supongamos que se pueden distinguir, 
llamémoslas moneda 1 y moneda 2. Ahora tenemos cuatro posibles resultados:
AA, AS, SA, SS, (la primer letra corresponde a la cara observada en la 
moneda 1 y la segunda en la moneda 2). Si estos 4 resultados son igualmente 
probables entonces el evento AA tiene posibilidad de 1/4.

¿Cuál es la respuesta correcta?  

En cuanto a teoría formal todas son correctas, cada escenario tiene supuestos
de resultados equiprobables claramente enunciados y en base a éstos determina
una probabilidad de manera correcta; sin embargo, los supuestos son diferentes
y por tanto también las conclusiones. Únicamente una de las soluciones puede
ser consistente con la interpretación frecuentista, ¿cuál es?

La primer respuesta es incorrecta pues supone probabilidad cero para el evento 
águila y sol. La solución dos, por otra parte, no es fácil de desacreditar, así
que realicemos el experimento para encontrar la respuesta:

```{r}
n <- 10000
moneda_1 <- sample(c("A", "S"), n, replace = TRUE)
moneda_2 <- sample(c("A", "S"), n, replace = TRUE)
sum(moneda_1 == moneda_2 & moneda_1 =="A") / n
```

La respuesta 3 es la correcta, y lo que vemos es que incluso cuando el supuesto
de igualmente probables es apropiado a un cierto nivel de descripción 
determinado, este _nivel_ no es algo que se pueda juzgar usando únicamente
matemáticas, sino que se debe juzgar usando una interpretación de la 
probabilidad, como frecuencias relativas en ensayos. Más aún, hay ejemplos
donde las monedas no son _justas_, o el sexo de un bebé recién nacido, donde 
el supuesto de equiprobabilidad no es adecuado.

#### Simulación para el cálculo de probabilidades
En el ejemplo anterior vimos que puede ser sencillo usar simulación para calcular
probabilidades, pues usando la interpretación de frecuencia relativa simplemente
hace falta simular el experimento y contar los casos favorables entre el
total de casos. Veamos un ejemplo más para familiarizarnos con este uso de 
simulación.

##### Ejemplo: La ruina del jugador 
* Un jugador tiene $100, y va a apostar en un juego donde
la probabilidad de ganar es p = 0.47 (e.g. una ruleta 18/38), si gana recibe el 
doble de lo que arriesgó, si no gana pierde todo lo que apostó.

* Cada vez que juega puede apostar cualquier cantidad siempre y cuando sea menor 
o igual al dinero que tiene en ese momento. 

* El jugador dejará de jugar cuando su capital sea $0 o cuando gane $200.

* El jugador busca una estrategia que le ayude a aumentar su probabilidad de 
ganar y te pregunta: ¿Cuál es la probabilidad de ganar si apuesto en incrementos 
de $5 cada vez que apuesto? ¿Cuál es la probabilidad si apuesto todo en una 
jugada?

```{r, cache=TRUE}
apostar <- function(dinero = 100, apuesta = 5, tope = 200, p = 0.47){
    while(0 < dinero & dinero < tope){
        if(runif(1) < p){
            dinero <- dinero + apuesta
        } 
        else{
            dinero <- dinero - apuesta
        }
    }
    dinero > 0
}
n_juegos <- 5000
juegos <- rerun(n_juegos, apostar()) %>% flatten_dbl()
mean(juegos)

juegos <- rerun(n_juegos, apostar(apuesta = 5)) %>% flatten_dbl()
mean(juegos)
```

La solución analítica la pueden leer en este documento de [caminatas aleatorias](http://web.mit.edu/neboat/Public/6.042/randomwalks.pdf):
```{r}
p = 0.47
1 - (1 - (p / (1 - p)) ^ (100 / 5)) / (1 - (p / (1 - p)) ^ (200 / 5)) # apostando de 5 en 5
1 - (1 - (p / (1 - p)) ^ (100 / 50)) / (1 - (p / (1 - p)) ^ (200 / 50)) # apostando de 50 en 50
```

![](../imagenes/manicule2.jpg) **Urna**: 10 personas (con nombres distintos) escriben sus nombres y los ponen en una urna, después seleccionan un nombre (al azar). 

* Sea A el evento en el que ninguna persona selecciona su nombre, ¿Cuál es la
probabilidad del evento A?  

* Supongamos que hay 3 personas con el mismo nombre, ¿Cómo calcularías la
probabilidad del evento A en este nuevo experimento?


****


### Probabilidad: definición matemática
Desde un punto de vista puramente matemático, la probabilidad se define como
una función de eventos. Los eventos se representan como conjuntos, y suponemos 
que la función de probabilidad satisface las reglas básicas de proporción. Antes
de definir estas reglas consideremos la representación de los eventos como 
subconjuntos de un espacio de resultados.

Supongamos que tenemos un espacio de resultados $\Omega$, y que todos los 
eventos de interés están representados como subconjuntos de $\Omega$. Podemos
pensar en $\Omega$ como una representación de todas las situaciones que pueden
ocurrir, no suponemos que es finito, ni que los eventos son igualmente probables.

Las reglas de la probabilidad involucran relaciones lógicas entre eventos; estas 
se traducen a relaciones de conjuntos. Por ejemplo, si C es el evento que ocurre
si sucede A o si sucede B, entonces el conjunto de maneras en las que ocurre C
es la unión del conjunto de maneras en que ocurre A y el conjunto de maneras en 
que ocurre B. Veamos como se traduce de eventos a conjuntos

Lenguaje de eventos | Lenguaje de conjuntos | Notación de conjuntos
--------------------|-----------------------|----------------------
Espacio de resultados| conjunto universal   | $\Omega$
evento              | subconjunto de $\Omega$| $A,B,C,...$
evento imposible    | conjunto vacío        | $\emptyset$
no A, opuesto de A  |complemento de A       | $A^c$
A o B               |unión de A y B         | $A\cup B$
tanto A como B      | intersección de A y B | $AB,A\cap B$ 
A y B mutuamente excluyentes |A y B disjuntos | $AB=\emptyset$
si A entonces B     | A es subconjunto de B | $A\subset B$


#### Particiones y axiomas de probabilidad
<div class="caja">
Decimos que un conjunto de $n$ eventos $B_1,...,B_n$ es una **partición** del evento 
$B$ si $B=B_1 \cup B_2 \cup \cdot\cdot\cdot \cup B_n$ y los eventos 
$B_1,...,B_n$ son mutuamente excluyentes. 
</div>

<div class="caja">
Una función $P$ es una **función de probabilidad** si satisface las siguientes condiciones:

1. Un valor de probabilidad debe ser no-negativo: 
$$P(B) \geq 0$$ para cualquier evento $B$  
2. La suma de las probabilidades a través de todos los posibles eventos en el 
espacio de resultados debe ser 1 (i.e. uno de los eventos en el espacio de 
resultados debe ocurrir). 
$$P(\Omega) = 1$$
3. Si $B_1,...,B_n$ es una partición del evento $B$ entonces, la probabilidad 
de que ocurra B es la suma de las probabilidades individuales:
$$P(B)=P(B_1)+P(B_2) + \cdot\cdot\cdot +P(B_n)$$
</div>

##### Propiedades de la función de probabilidad:
* $P(A^c) = 1 - P(A)$    
* $P(\emptyset)=0$  
* Si $A \subset B$ entonces $P(A) \le P(B)$  
* $0\le P(A) \le 1$
* La regla general de la suma: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$

#### Distribuiones de probabilidad
Una distribución de probabilidad es simplemente una lista de todos los posibles
valores y sus probabilidades correspondientes (en el caso discreto). 

resultado $\omega$          | a    | b | c | d | e| $\cdot\cdot\cdot$  
----------------------------|------|---|---|---|--|---------------- 
**probabilidad $P(\omega)$**|$P(a)$|$P(b)$|$P(c)$|$P(d)$|$P(e)$|$\cdot\cdot\cdot$


Podemos pensar en el término distribución como una masa distribuida sobre un 
área o volumen $\Omega$, y $P(A)$ representa la proporción de esa masa en el 
subconjunto $A$. 

<!-- Con esta imagen en mente, las reglas de probabilidad son 
intuitivas. Pensemos que B puede o no ocurrir, P(B) es una medida de que 
tan posible es que ocurra.

Remark técnico: si omega es infinito se asume que hay una regla de suma 
similar para particiones de un evento en una sucesión infinita -->

#### Distribución empírica
Sea $(x_1,x_2,...,x_n)$ una lista de $n$ números, podemos pensar que $x_i$ es la 
i-ésima medida de algo en una serie de mediciones. La distribución empírica de
la lista de $n$ números es la distribución en la línea $(-\infty, \infty)$ 
definida como 
$$P_n(a,b)=\#\{i: 1 \le i \le n, a < x_i < b\}/n$$

Esto es, $P_n(a,b)$ es la proporción de los $n$ números en la lista que se 
ubican en el intervalo $(a,b)$. Para entender la interpretación probabilista, 
imaginemos $n$ boletos en una caja, cada boleto tiene escrito el número $x_i$,
después elegimos un boleto al azar y $P_n(a,b)$ es la probabilidad de que 
el número escrito en el boleto que elegimos caiga en el intervalo $(a,b)$. 
Entonces, la distribución empírica de una lista es la distribución de un número 
elegido de manera aleatoria de la lista.

Podemos mostrar la distribución empírica de una lista de datos mediante un
histograma

Tenemos una muestra aleatoria de 100 lanzamientos de un dado, 

```{r}
dado <- read_delim("data/dado.csv", " ", escape_double = FALSE, trim_ws = TRUE)
prop.table(table(dado$observado))
```

La distribución empírica es (0.13, 0.19, 0.10, 0.17, 0.14, 0.27), en este caso
el valor $x_i$ es discreto (1, 2, 3, 4, 5 o 6), por lo que la distribución 
empírica se describe con una gráfica de barras:

```{r, fig.height=3, fig.width=3.5}
ggplot(dado, aes(x = observado)) + 
    geom_bar(aes(y = ..prop..)) +
    labs(y = "")
```

Veamos un caso donde $x_i$ es continua, inspeccionaremos la distribución empírica
de la variable ozono en la base de datos _airquality_.

```{r, fig.height=3, fig.width=5}
data(airquality)
glimpse(airquality)
```

¿Cómo calculamos la probabilidad de $x \in (0, 20)$?

```{r}
ozone_1 <- airquality$Ozone[!(is.na(airquality$Ozone))]
n <- length(ozone_1)
n # calculamos n (tamaño de muestra)
ozone_ab <- ozone_1[0 < ozone_1 & ozone_1 < 20]
ozone_ab
n_ab <- length(ozone_ab)  # contamos cuantas observaciones pertenecen al evento (0, 20)
n_ab/n
```

Y podemos graficar el histograma del ozono.

```{r, fig.height=3, fig.width=5}
ggplot(airquality, aes(x = Ozone)) +
    #geom_histogram(binwidth = 10, aes(y = ..density..)) + 
  geom_density() +
    labs(y = "")
```

Un histograma _suaviza_ los datos para mostrar la forma general de la 
distribución empírica.

****

### Probabilidad condicional e independencia
Comenzaremos ilustrando la idea de probabilidad condicional mediante un ejemplo:

##### Lanzamiento consecutivo de una moneda
Supongamos que lanzamos una moneda tres veces, si apostamos que saldrán 2 o más
águilas, tenemos mayor oportunidad de ganar si el primer lanzamiento resulta en 
águila en contraste con que el primer lanzamiento resulte en sol. Para ser más
exactos, supongamos que las 8 posibles combinaciones de los resultados son
igualmente probables:

```{r}
volado <- c("A", "S") 
volados <- volado %>% 
    crossing(volado) %>% 
    crossing(volado)
volados
```

Entonces, la probabilidad no condicional, de el evento $A$: que se observen al 
menos dos soles es $4/8 = 0.5$. Ahora, condicional a que el primer lanzamiento
fue águila, 

```{r}
volados %>% 
    filter(`.` == "A")
```

el evento $A$ ocurre si se observa al menos un águila en los siguientes dos 
lanzamientos, esto tiene una probabilidad de $3/4$. Entonces, decimos que la 
probabilidad condicional de $A$ (que se observen al menos dos
soles) condicional a $B$ (que el primer lanzamiento haya resultado en águila)
es $3/4$ y se denota: 
$$P(A \vert B) = 3/4$$
Notemos que los 3 eventos que resultan en que gane la apuesta, condicional
a que se observó un águila en el primer volado es la intersección de los
eventos $A$ y $B$. 

#### Fórmula de conteo $P(A\vert B)$
<div class="caja">
Para un conjunto finito $\Omega$ de resultados igualmente probables, y eventos
$A$, $B$ tales que $P(B) > 0$, la **probabilidad condicional** de $A$ dado
$B$ es 
$$P(A\vert B)=\frac{\#(A\cap B)}{\#B}$$
la proporción de los resultados en $B$ que también están en $A$.
</div>

![](../imagenes/manicule2.jpg) Una urna contiene 10 sobres: 4 negros y 6 blancos,
Adentro de cada sobre hay un boleto con una marca de ganar o perder, el número 
de boletos ganadores y perdedores es como sigue:

sobre  ganar   perder
-----  ------- ------
blanco  2       4
negro   2       2

Supongamos que se extrajo un sobre negro pero aún no se abre, ¿Cuál es la 
probabilidad de ganar condicional a que se extrajo un sobre negro?  
¿Cómo se compara con la probabilidad no condicional de ganar?


![](../imagenes/manicule2.jpg) En el juego de bridge, se dividen las 52 cartas 
en 4 jugadores -llamados Este, Oeste, Norte y Sur, si Norte y Sur:  

* ¿cuál es la probabilidad de que Este tenga 3 espadas?  

* Si Norte y Sur tienen un total de 8 espadas, ¿cuál es la probabilidad de que 
Este tenga 3 espadas de las 5 restantes?

#### Interpretación frecuentista de la probabilidad condicional
Este concepto se ilustra en el ejercicio anterior, si $P(A) \approx P_n(A)$ 
(la frecuencia relativa de A) conforme el número de ensayos $n$ aumenta, 
entonces $P(A\vert B)$ se aproxima a la frecuencia relativa de ensayos que producen 
$A$ dentro del conjunto de ensayos en los que ocurre $B$:
$$P(A\vert B) = \frac{P(A \cap B)}{P(B)}$$


##### Ejemplo: Áreas relativas
Supongamos que tenemos un rectángulo principal (R) con un círculo (B) y un 
rectángulo (A) más chico que se intersectan en su interior. Supongamos ahora que 
la ubicación del punto se revela en 2 etapas, primero se indica si el punto
está o no en el círculo, y después se indica si está en el rectángulo 
interior. Antes de obtener información,  
¿Cuál es la probabilidad de que el punto esté en el rectángulo interior? 
$$P(A) = \frac{Área(A)}{Área(R)}$$
Ahora, si sabemos que el punto esta en el círculo, ¿cuál es la probabilidad
de que el punto esté en el interior del rectángulo chico?
$$P(A\vert B) = \frac{Área(A \cap B)}{Área(B)}$$

Notemos que en este caso la fórmula de probabilidad condicional corresponde a la
idea de condicional a que el punto está en $B$, áreas iguales corresponden a
igual probabilidad dentro de $B$.

#### Regla de la multiplicación
En los ejemplos anteriores calculamos la probabilidad condicional a partir de 
probabilidades no condicionales ($P(B), P(A\cap B)$); sin embargo, en las 
aplicaciones es común tener eventos tales que la probabilidad condicional 
$P(A\vert B)$ y la probabilidad $P(B)$ son más fáciles de conocer que la probabilidad
$P(A \cap B)$. 

<div class="caja">
**Regla de la multiplicación**: $P(A \cap B) = P(A\vert B)P(B)$
</div>

La regla de la multiplicación es muy natural en escenarios donde un evento $A$
esta determinado por un resultado que ocurre en etapas, y $B$ es un evento que 
depende únicamente de la primera etapa.

##### Ejemplo: Seleccionando una camada, después un cachorro
Supongamos que tenemos 2 camadas de labradores, en la primer camada hay 2 
cachorros color negro y 2 chocolate, en la segunda camada hay 1 cachorro color negro 
y 2 miel. El experimento es como sigue: lanzo una moneda justa, si sale sol
elijo un perro al azar de la camada uno y si el resultado es águila elijo 
un perro al azar de la camada dos.  

¿Cuál es la probabilidad de que elija un perro color chocolate? 

Sea A el evento: elijo un perro miel, y B elijo la camada 1. Entonces para 
calcular $P(A) = P(A \cap B)$ usamos la regla de la multiplicación.  
Notemos primero que $P(B) = 1/2 = P(B^c)$  
Y $P(A\vert B)=1/2$
Por tanto $P(A) = 1/4$.

![](../imagenes/manicule2.jpg) ¿Cuál es la probabilidad de que elija un cachorro color negro?

#### Promedio de probabilidades condicionales
El ejercicio anterior ilustra la regla de del promedio de probabilidades
condicionales: para cualquier par de eventos $A$ y $B$, la probabilidad total 
$P(A)$ es el promedio de 2 probabilidades condicionales $P(A\vert B)$ y $P(A\vert B^c)$, 
donde los pesos son $P(B)$ y $P(B^c)$:
$$P(A) = P(A\vert B)P(B) + P(A\vert B^c)P(B^c)$$

El evento $B$ define una partición del espacio de resultados $\Omega$ en 2
eventos $B$ y $B^c$, podemos extender la fórmula a un caso más general: sean
$B_1, B_2, ..., B_n$ una partición del espacio de resultados $\Omega$, para 
cualquier evento $A$, los eventos $A\cap B_1,...,A\cap B_n$ forman una partición
de $A$, por lo tanto
$$P(A)=P(A\cap B_1)+\cdot\cdot\cdot+A\cap B_n$$
y si aplicamos la regla de la  multiplicación a cada término,
$$P(A) = P(A\vert B_1)P(B_1)+\cdot\cdot\cdot+P(A\vert B_n)P(B_n)$$

##### Ejemplo: muestreo con/sin reemplazo
Supongamos que seleccionamos (al azar) dos cartas de una baraja, ¿cuál es la 
probabilidad de que la segunda carta sea negra?  
Sean $N$ y $R$ los eventos, que la primera carta sea negra y que la primera
carta sea roja, y sea $A$ el evento que la segunda carta sea negra, entonces
$$P(A) = P(A\vert B)P(B) + P(A\vert R) P(R)$$

![](../imagenes/manicule2.jpg) **Chabelo (Monty Hall)**
Supongamos que estamos jugando las catafixias de Chabelo, en este juego hay
3 _catafixias_: 2 de ellas están vacías y una tiene un premio,  

1. El juego comienza cuando escoges una catafixia.  
2. A continuación Chabelo abre una catafixia vacía de las dos catafixias restantes. 
3. Tu eliges si te mantienes con tu catafixia o cambias a la otra que 
continúa cerrada.
4. Chabelo abre tu segunda elección de catafixia y se revela si ganaste.

¿Cuál es la probabilidad de que ganes si cambias de catafixia?

#### Regla de Bayes
Las reglas de probabilidad condicional que describimos en la sección anterior
son la base de la regla de Bayes. Antes de escribir la regla de manera formal 
veamos un ejemplo.

##### 3 camadas
Supongamos que tenemos 3 camadas de labradores en un criadero:

Camada | negro | miel
-------|-------|-----
1      | 1     | 1
2      | 2     | 1
3      | 3     | 1

Para vender un cachorro elijo una camada de manera aleatoria, y después elijo un 
cachorro de manera aleatoria de la camada seleccionada y lo entrego al nuevo 
dueño. Sabiendo la composición de las camadas antes de extraer el cachorro, 
ofrezco un descuento si adivinan de que camada provino.  

Si te entrego un cachorro negro ¿Qué camada seleccionarías y cuál es la 
probabilidad de elegir la correcta?

Veamos que la regla de Bayes se deriva de las reglas de probabilidad condicional.

<div class = "caja">
**Regla de Bayes**. Sea $B_1,...,B_n$ una partición de los posibles 
resultados,
$$P(B_i\vert A) = \frac{P(A\vert B_i)P(B_i)}{P(A\vert B_1)P(B_1)+ \cdot\cdot\cdot + 
P(A\vert B_n)P(B_n)}$$
</div>
![](../imagenes/manicule2.jpg) [La intuición es engañosa](http://www.amazon.com/The-Drunkards-Walk-Randomness-Rules/dp/0307275175): En estudios en Alemania y EUA, investigadores
le pidieron a médicos que estimaran la probabilidad de que una mujer 
asintomática entre los 40 y 50 años tuviera cáncer de mama si su mamograma 
era positivo. Se les explicó que el 7\% de los mamogramas indican cáncer cuando
no lo hay (falsos positivos). Adicional mente, se le explicó a los médicos que 
la incidencia de cáncer de mama en ese grupo de edad es 0.8\% y la tasa de 
falsos negativos de 10\%. En Alemania, un tercio de los médicos determinaron
que la probabilidad era cercana al 90\% y la mediana de las estimaciones fue
70\%. En EUA 95 de 100 médicos estimaron que la probabilidad rondaba el 75\%.
¿Cómo determinas la probabilidad de que una mujer con mamograma positivo tenga
cáncer?

#### Observaciones/resumen de probabilidad condicional
1. Si $P(B)>0$ entonces 
$$P(A\vert B)=\frac{P(A\cap B)}{P(B)}$$  
2. $P(\cdot\vert B)$ satisface las reglas de probabilidad para una $B$ fija. En general, $P(A\vert \cdot)$ no satisface las reglas de probabilidad para una $A$ fija.
3. En general $P(A\vert B) \ne P(B\vert A)$.

#### Independencia
Dos eventos, $A$, $B$ son **independientes** si la probabilidad de que ocurra 
$B$ no depende de si ocurre $A$ o no:

$$P(B\vert A) = P(B\vert A^c) = P(B)$$ 

esto es equivalente a: $A$, $B$ son **independientes** si la probabilidad de 
la intersección es el producto de las probabilidades:
$$P(A\cap B) = P(A)P(B)$$

La idea de independencia para más de dos eventos es una extensión natural de la
independencia de dos eventos. Por ejemplo, los eventos $A$, $B$ y $C$ son 
independientes si, primero $A$  y $B$ son independientes, ver definición de 
arriba, ahora si la probabilidad de que ocurra $C$ no depende de si ocurre $A$
o $B$ tenemos:
$$P(C\vert A\cap B) = P(C\vert A^c \cap B) = P(C\vert A\cap B^c) = P(C\vert A^c\cap B^c) = P(C)$$

y nuevamente es equivalente a la regla de la multiplicación: 
$$P(ABC)=P(A)P(B)P(C)$$
que se cumple si sustituimos cualquier número de eventos por sus complementos.

Entonces, la regla de la multiplicación para 3 eventos es en realidad la
combinación de $2^3=8$ reglas. La independencia para $n$ eventos se define en base a $2^n$ reglas de multiplicación (en realidad son $2^n - 1$ pues una es
trivial). Por tanto, a pesar de que la independencia es una idea intuitiva 
es difícil de verificar en la práctica.

##### Suponer independencia o derivar independencia
La independencia puede surgir de dos maneras, algunas veces suponemos de manera
explícita que dos eventos son independientes. Por ejemplo, cuando lanzamos
una moneda dos veces, usualmente asumimos que los lanzamientos son independientes, y esto refleja que la moneda no tiene memoria. En otras ocasiones derivamos
la independencia verificando que $P(A \cap B) = P(A)P(B)$. Por ejemplo cuando 
lanzamos un dado justo, sea $A=\{2,4,5\}$ y $B=\{1,2,3,4\}$, entonces $A\cup B = \{2,4\}$, $P(A \cup B)=2/6 = P(A)P(B)$, por tanto $A$ y $B$ son independientes.

Supongamos que $A$ y $B$ son dos eventos mutuamente excluyentes, tales que
$P(A)>0$ y $P(B)>0$ ¿pueden ser independientes?


**** 

### Variables aleatorias
La estadística esta ligada a datos, por tanto debemos encontrar una manera de
relacionar el espacios de resultados y los eventos a los datos: la liga es el 
concepto de variable aleatoria.

<div class="caja">
Una **variable aleatoria** $X$ es un mapeo entre el espacio de resultados y los 
números reales. 
</div>

##### Ejemplos
1. Supongamos que lanzamos una moneda 2 veces. Sea $X(\omega)$ el número de 
veces que obtenemos águila en la sucesión $\omega$. Por ejemplo, si 
$\omega=AA$ entonces $X(\omega)=2$, podemos hacer la tabla completa de posibilidades:

$\omega \in \Omega$ | AA | AS | SA | SS
--------------------|----|----|----|---
$X(\omega) = x$     | 2  |  1 |  1 | 0

Si observamos el segundo renglón de la tabla notamos que el soporte de $X$ (el
conjunto de valores que toma X) es $\Omega_X=\{0, 1, 2\}$.

2. Supongamos que lanzamos una moneda hasta observar un águila, en esta caso
el espacio de resultados es $\Omega=\{A, SA, SSA, SSSA,...\}$ y ahora definimos
la variable aleatoria $Y$ como el número de soles antes de observar la primer
águila, entonces el soporte de $Y$ es $\Omega_Y=\{0, 1, 2, ...\}$.

3. Sea $\Omega=\{(x,y): x^2 + y^2 \le 1\}$ el círculo unitario. Consideremos 
seleccionar un punto de manera aleatoria de $\Omega$, entonces un resultado
típico es de la forma $\omega=(x, y)$, y podemos definir una variable aleatoria
$X(\omega)=x$, $Y(\omega)=y$, $Z(\omega)=x+y$ o $W(\omega)=\sqrt{x^2+y^2}$.

Otra manera de ver una variable aleatoria es como una variable cuyo valor esta
determinado por el resultado de un experimento aleatorio.

Ahora dada una variable aleatoria $X$ y un subconjuto $A=(a,b)$ de la recta real 
definimos $$X^{-1}(A) = \{\omega \in \Omega: X(\omega) \in A\}$$
entonces, 
$$P(X \in A) = P(X^{-1}(A)) = P(\{\omega \in \Omega: X(\omega) \in A\})$$

Volviendo al ejemplo del lanzamiento de una moneda dos veces, podemos definir
$A = 1$, entonces, la distribución de la variable aleatoria $X$ es
$X^{-1}(A) = \{AS,SA\}$ y $P(X \in A) = 1/2$

Si $X$ toma únicamente un número finito de valores, la distribución
de X esta determinada por las probabilidades de valores individuales
$$P(X = x), x \in \Omega_X$$
por medio de la regla de la suma:

$$P(X \in B) = \sum_{x \in B}P(X = x)$$

Dos variables aleatorias tienen la misma distribución si $X$ e $Y$ tienen el mismo soporte, y si para cualquier valor $v$ en el soporte
$$P(X=v)=P(Y=v)$$.

### Esperanza
<div class="caja">
La **esperanza** (valor esperado o media) de una variable aleatoria $X$,
es la media de la distribución $X$, esto es,
$$E(X)=\sum_{x\in \Omega_x} x P(X=x)$$
el promedio de todos los posibles valores de $X$ ponderados por sus probabilidades.
</div>

Por ejemplo, si $X$ toma únicamente dos posibles valores, $a,b$ con
probabilidad $P(a)$ y $P(b)$ entonces
$$E(X)=aP(a)+bP(b).$$

Ejemplo: Supongamos que $X$ es el valor que se produce cuando tiro un
dado justo. Entonces,
$$E(X)=1\cdot P(X=1) +2\cdot P(X=2) +3\cdot P(X=3) +4\cdot P(X=4) +5\cdot P(X=5) +6\cdot P(X=6) = 3.5$$
Lo que nos dice que si tiramos el dado muchas veces deberíamos esperar que el promedio de las tiradas sea cercano a 3.5.

**Esperanza como un promedio cuando n es grande**. Si vemos las probabilidades de los valores de $X$ como una aproximación de frecuencias relativas cuando n es grande, entonces $E(X)$ es aproximadamente el valor promedio del valor de $X$ cuando n es grande.

```{r}
x <- rnorm(10000, mean = 10)
mean(x)
```

<!--
**Esperanza y predicción**. Supongamos que deseamos predecir el valor de una variable aleatoria $X$. ¿Cuál es el mejor predictor de X? Para responder la pregunta es preciso seleccionar un criterio. Es común que el criterio 
sea minimizar el 
-->

La esperanza cumple las siguientes reglas: 

1. **Constantes**. La esperanza de una variable aleatoria constante
es su valor constante,
$$E(c) = c$$

2. **Indicadoras**. Si $I_A$ es la función indicadora del evento $A$, 
$$E(I_A) = P(A)$$

3. **Funciones**. Típicamente, $E[g(X)]\ne g[E(X)]$, pero
$$E[g(X)] = \sum_{x \in \Omega_X} g(x) P(X=x)$$

4. **Factores constantes**. Para una constante c,
$$E(cX)=cE(X)$$

5. **Adición**. Para cualquier par de variables aleatorias $X$, $Y$,
$$E(X+Y) = E(X)+E(Y)$$

6. **Multiplicación**. Típicamente $E(XY) \ne E(X)E(Y)$, pero
si $X$ y $Y$ son independientes, entonces $$E(XY)=E(X)E(Y)$$





<!-- Supongamos que lanzamos una moneda al aire y definimos la variable aleatoria
$Z$ como el tiempo en segundos que transcurre antes de que la moneda toque el suelo. En este caso el espacio de resultados es inconveniente de describir. Sin
embargo, el soporte de $Z$ sería $(0, \infty)$, es claro que el conjunto $(0, \infty)$ es demasiado grande, pero veremos que en la práctica a veces es
conveniente estudiar el soporte extendido. -->


### Varianza y desviación estándar
Si intentamos predecir el valor de una variable aleatoria
usando su media $E(X)=\mu$, vamos a fallar por una cantidad aleatoria $X-\mu$. Suele ser importante tener una idea de que tan grande será esta desviación. Debido a que
$$E(X-\mu) = E(X)-\mu=0$$
es necesario considerar la diferencia absoluta o la diferencia al cuadrado de $X-\mu$ con el fin de tener una idea del tamaño de la desviación sin importar el signo de esta. 

**Varianza y desviación estándar**. La varianza de $X$, denotada $var(X)=\sigma^2$ es la media de la desviación cuadrada de $X$ respecto a su valor esperado $\mu=E(X)$:
$$\sigma^2(X)=var(X)=E(X-\mu)^2$$
La desviación estándar de $X$, es la raíz cuadrada de la varianza de X:
$$\sigma(X)=se(X)=\sqrt{var(X)}$$

Intuitivamente, $se(X)$ es una medida de la dispersión de la distribución de $X$ alrededor de su media. Debido a que la varianza es el valor central de la distribución de $(X-\mu)^2$, su raíz cuadrada da una idea del tamaño típico de la desviación absoluta $|X-\mu|$. Notemos que $E(X)$, $var(X)$ y $se(X)$ están determinados por $X$, de tal manera que si dos variables aleatorias tienen la misma distribución, 
también tienen la misma media, varianza y desviación estándar.






